[["index.html", "Bookdown Analisis Series Tiempo Chapter 1 Contexto inicial", " Bookdown Analisis Series Tiempo Santiago Restrepo Aguilar 2024-11-11 Chapter 1 Contexto inicial El mundo como lo conocemos ha estado enfrentando multiples sucesos que han afectado de manera imprevista la economia global. Situaciones tales como los conflictos belicos en ucrania e israel, las elecciones de Venezuela, la crisis energetica, la pandemia mundial por covid-19, y si nos vamos mas atras, la crisis financiera del 2008. etc… Han ido afectando la calidad de vida de los ciudadanos de multiples paises al verse envueltos en la constante subida de precios relacionada a las importaciones y las exportaciones, entre estas subidas se destaca el aumento creciente del precio de cambio del dolar (que es actualmente la moneda de cambio mundial) que ha derivado en la devaluacion de otras monedas de uso nacional (incluyendo el peso). Latinoamerica, en especial colombia, no es indiferente a los diversos cambios que sufre la economia mundial. Sin irnos muy en el pasado, desde las ultimas elecciones, el pais ha experimentado duros golpes financieros y economicos que han derivado en multiples problemas y (como es usual) en protestas de todo tipo, tomando como ejemplo un hecho reciente, el incremento sin escalas de la gasolina y el ACPM que ha influido enormemente en el dia a dia de los colombianos. Estos ultimos sucesos han dado mucho de que hablar y nos hace cuestionar de si el gobierno ha o esta incentivando un plan de accion para poder combatir estos imprevistos. Aun asi, es completamente logico decir que es necesario hacer un estudio sobre el estado financiero actual del pais y como este ha cambiado los ultimos años. Esto con el objectivo de: Determinar una posible tendencia o patron en los comportamientos que ayude a explicar un poco como se llego a la situacion actual Poder predecir en tiempos futuros el estado que tomara dicha tendencia y asi proponer estrategias que ayuden a combatir dicho resultado, basicamente, para prevenirnos de alguna eventualidad futura. Tomando en cuenta todo lo mencionado anteriormente. La informacion que se estudiara a lo largo del curso y a lo cual le haremos un analisis, es informacion de tipo financiera, mas especificamente: ‘GPD per Capita’ del pais colombiano de forma anual. Toda la informacion se encuentra en la base de datos ‘ourworldindata.org’ a travez del siguiente link: https://ourworldindata.org/grapher/gdp-per-capita-worldbank?tab=chart&amp;country=~COL. No se requieren permisos especiales y la disponibilidad de la informacion hara mas facil el analisis correspondiente. es notorio que la propuesta de informacion no abarcara todo lo que conlleva e influye en la economia del pais (dado que esta se rige por multiples variables y datos). Sin embargo, es un buen punto de partida para responder a los objectivos que queremos ya que el ‘GPD per capita’ es un tipo de dato general que abarca no solo la inflacion sino tambien el costo de vivienda promedio. Como ultimo punto a aclarar, es claro que se escogio una serie de tiempo anual y no mensual como se suele hacer. Porque? la razon principal de esto es el afrontar el reto de ver como se trabajan con series de tiempo de este tipo, tomando en cuenta que de manera profesional no siempre tendremos a disposicion datos de una gran cantidad en nuestro estudio. Entonces se trabajara una serie de datos anual para ver como es el margen de accion para este tipo de series no tan frecuentes y analizar que posibles caminos podemos tomar. "],["intro.html", "Chapter 2 Preparacion de la serie 2.1 Evaluacion de nuestra serie de tiempo inicial 2.2 Una Nueva Serie de tiempo", " Chapter 2 Preparacion de la serie Comenzamos entonces haciendo estudios primarios a nuestros datos. Comenzamos cargando algunas librerias de interes library(forecast) library(tseries) library(ggplot2) library(changepoint) library(readxl) library(dplyr) library(zoo) library(dygraphs) library(seasonal) library(TSA) 2.1 Evaluacion de nuestra serie de tiempo inicial Empezaremos definiendo una serie de tiempo en los datos relacionados al ‘GPD per capita’: Los datos son tomados de forma anual entonces nuestra serie de tiempo mantendra el mismo formato de tiempo (En años). la fecha de interes sera a partir de 1990 (ligado a la crisis de exportaciones) y la fecha de finalizacion sera en 2022 (ligado al fin de la pandemia y al inicio del conflicto rusia-ucrania) gpd_data &lt;- read.csv(&quot;gpd_per_capita.csv&quot;) gdp_colombia &lt;- gpd_data %&gt;% filter(Entity == &quot;Colombia&quot;) Datos &lt;- gdp_colombia$GDP.per.capita..PPP..constant.2017.international... ST_COL &lt;- ts(Datos, frequency=1, start=c(1990)) (ST_COL) ## Time Series: ## Start = 1990 ## End = 2022 ## Frequency = 1 ## [1] 8434.959 8430.223 8598.992 8885.187 9220.502 9518.260 9538.272 ## [8] 9691.028 9578.656 9023.621 9138.319 9146.405 9232.627 9453.328 ## [15] 9816.277 10150.708 10692.728 11272.578 11507.525 11507.717 11890.203 ## [22] 12578.016 12934.966 13465.075 13938.231 14215.688 14358.168 14334.915 ## [29] 14426.435 14616.135 13358.298 14661.213 15616.752 Veamos datos generales summary(ST_COL) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 8430 9233 10693 11310 13465 15617 mean(ST_COL) ## [1] 11310.06 var(ST_COL) ## [1] 5318247 Se observan 3 cosas: El Maximo ‘GDP per capita’ registrado en la historia del pais (hasta 2022) es de 12617, contrario al minimo reghistrado que es de 8430 El promedio registrado a travez de los años es de aproximadamente 11310 luego observamos la serie de tiempo en forma de grafica La varianza es notablemente alta e indica que los datos estan muy dispersos alrededor del promedio, lo que indica que este ultimo no es un indicador recomendado para determinar el comportamiento que tendra el pais respecto a esta metrica en los años que vienen Viendo el grafico de la serie de tiempo plot(ST_COL, main=&quot; &quot;, ylab=&quot;Valor&quot;,col=&quot;deepskyblue&quot;,xlab=&quot;Años&quot;) title(main=&quot;Valores anuales del gdp per capita del pais colombiano&quot;) En el grafico podemos evidenciar una creciente tendencia de los valores a partir de 1990, eso es obvio dado que a partir de estos años posteriores se han ido incrementando mas el proceso de globalizacion con el tema de exportaciones y aperturas del comercio que se afianzaron con los años. Sin embargo podemos evidenciar tambien en la grafica dos desaceleraciones notables: Entre 1998 y 2000, la explicacion historica a esta desaceleracion fuerte se da a que durante estas epocas el pais estuvo azotado por multiples conflictos entre el ejercito, las autodefensas y las FARC, destinando la mayor parte de los recursos del estado al ejercito y a la asistencia de las multiples victimas civiles sufridas Entre 2019 y 2020, la explicacion historica a esta aun mas fuerte desaceleracion se da a un fenomeno mundial, claramente la pandemia por covid-19 que puso en jaque la economia global de la cual colombia tuvo que cerrar multiples importaciones y exportaciones como medidas preventivas Ahora, no es suficiente solo concretar nuestra base de datos en una serie de tiempo. Es vital determinar si nuestros datos presentan estacionalidad o no (concretamente, si nuestra base de datos presenta ciertos patrones recurrentes que se repiten en ciertos intervalo de tiempo). Para esta primera deteccion usaremos una grafica de rezagos Para esta tarea usaremos la funcion lag.plot y nos apegaremos a hacerlo en 9 rezagos lag.plot(ST_COL, 9, do.lines = FALSE) Viendo cada rezago de manera cuidadosa, podemos observar un comportamiento identificable en el grafico 1, mas especificamente una alineacion diagonal. Esto nos indica que existe la posibilidad de que nuestra serie de tiempo presente una tendencia, sin embargo, este comportamiento no se vuelve a repetir en los otros rezagos y no se identifica mas comportamientos identificables en las otras graficas, por ende podemos decir que nuestros datos no presentan un patron estacional concreto o que la estacionalidad es muy debil Que significa esto? que hay que eliminar los componentes estacionales debiles de nuestro modelo, pues estos no presentan algun aporte ni ninguna diferencia significativa frente a datos que no lo tienen. El siguiente paso seria filtrar el comportamiento estacional de nuestra serie de tiempo. Sin embargo hay un problema y es que nuestra serie de tiempo es anual, esto dificultaria mas la tarea ya que la estacionalidad usualmente se presenta en intervalos mensuales o a lo mucho trimestrales, lo que complica mas el proceso de depuracion, sin embargo hay una solucion a esto y es crear una nueva serie de tiempo de frecuencia trimestral usando datos aproximados a partir de los originales. Investigando un poco mas, el paquete ‘zoo’ nos permite crear datos adicionales usando tecnicas de interpolacion. Esto es muy util ya que estos datos sirven como aproximaciones que pueden añadirse en nuestra serie de tiempo original, para poder convertirla luego en una serie de tiempo ya sea trimestral o mensual que es lo que buscamos. 2.2 Una Nueva Serie de tiempo El primer paso es convertir nuestra serie en un objeto de tipo ‘zoo’, esto para volverla una serie de tiempo flexible y poder aplicarle las tecnicas de interpolacion años &lt;- 1990:2022 COL_zoo &lt;- zoo(ST_COL, order.by = años) A continuacion utilizaremos interpolacion lineal para crear datos aproximados y definir la serie equivalente en tiempos trimestrales. Hay que tener en cuenta que usamos interpolacion lineal porque es el metodo de interpolacion mas sencillo que ofrece el paquete Zoo y porque concuerda mejor con la aproximacion diagonal que presento el primer retazo en la serie de graficos anteriores, luego definimos la nueva serie de tiempo de frecuencia trimestral debido a que es el periodo de tiempo que mas se acerca a los datos anuales, tampoco buscamos tentar mucho el nivel de aproximacion que podamos obtener al crear muchisimos datos entre cada dato original. # Crear una secuencia de fechas trimestrales(a partir de las funcion as.Date mostrada en los contenidps) start_year &lt;- as.Date(&quot;1990-01-01&quot;) end_year &lt;- as.Date(&quot;2022-12-31&quot;) Fechas &lt;- seq(from = start_year, to = end_year, by = &quot;quarter&quot;)#Esta funcion crea un vector de fechas trimestrales, encontrado por investigacion #Se crea una serie de tiempo vacia que tiene como frecuencias las fechas trimestrales que creamos COL_zoo_trimestral &lt;- zoo(NA, order.by = Fechas) #Se va llenando la nueva serie con los datos ANUALES de nuestra serie original, pero los trimestres entre los años siguen vacios for (i in 1:length(años)) { year_start &lt;- which(index(COL_zoo_trimestral) == as.Date(paste(años[i], &quot;01-01&quot;, sep = &quot;-&quot;))) COL_zoo_trimestral[year_start] &lt;- ST_COL[i] } #Finalmente se lleman los datos trimestreales con aproximaciones por interpolacion lineal usando los datos anuales COL_zoo_trimestral &lt;- na.approx(COL_zoo_trimestral) Para mayor comodidad en la visualizacion de graficas (ya que ahora si contamos con mas datos), usaremos la libreria dygraphs, una libreria de visualizacion de series de tiempo propuesta en el debate ‘Visualizacion de series de tiempo’ dygraph(COL_zoo_trimestral) %&gt;% dyRangeSelector() # Agrega un selector de rango para el zoom summary(COL_zoo_trimestral) ## Index COL_zoo_trimestral ## Min. :1990-01-01 Min. : 8430 ## 1st Qu.:1998-01-01 1st Qu.: 9294 ## Median :2006-01-01 Median :10693 ## Mean :2005-12-31 Mean :11293 ## 3rd Qu.:2014-01-01 3rd Qu.:13682 ## Max. :2022-01-01 Max. :15617 Sin embargo nuevamente recordemos que trabajamos con datos aproximados asi que aunque las graficas se parezcan, aun habra ligeras diferencias comparadas con la realidad. Volvemos a convertir los datos a una serie de tiempo de tipo ts ST_TRIMESTRAL &lt;- ts(coredata(COL_zoo_trimestral), start = c(1990, 1), frequency = 4) Luego descomponemos la serie, analicemos su tendencia COL_DECOMP &lt;- decompose(ST_TRIMESTRAL) #Descompone la serie en tendencia, estacionalidad y ruido plot(COL_DECOMP$trend, main = &quot;Tendencia&quot;, col = &quot;blue&quot;, ylab = &quot;Valores&quot;) Aqui la serie es mayormente creciente(salvo por algunas fluctuaciones en secciones especificas) lo que evidencia una tendencia positiva SALVO en una caida abrupta y significativa, producto de un evento particular que afecto profundamente el comportamiento constante de los datos (Dicho evento claramente es la pandemia) Ajustemos la serie ahora por desestacionalidad para eliminar todo rastro de estacionalidad que la serie posee (ya que no es significativo trabajar con ella) EST_COL &lt;- seasadj(COL_DECOMP) # Elimina el componente estacional de la serie, devolviendola sin estos efectos plot(ST_TRIMESTRAL,main =&quot;GPD Per Capita ORIGINAL VS DESESTACIONALIZADO&quot;) lines(EST_COL, col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;Serie original&quot;, &quot;Serie desestacionalizada&quot;), col = c(&quot;blue&quot;, &quot;red&quot;), lty = 1) Luego podemos ver que el grafico desestacionalizado es exactamente igual al grafico original (salvo por unas minusculas diferencias que destacan a simple vista ), esto es obvio ya que en el analisis al grafico de rezagos, concluimos que la estacionalidad presente en nuestros datos era tan debil que no haria diferencia alguna si la eliminamos. Con esto ultimo listo ya es hora de poder proponer distintos modelos que nos ayuden a explicar el comportamiento de nuestra serie de tiempo esperando en lo mejor posible, encontrar el que mejor se ajuste a los datos y al que podamos aplicarle analisis de prediccion NOTA: NO se planea hacer predicciones usando los modelos propuestos aun hasta que llegue la hora de compararlos entre si y evaluar el alcance y precision de su prediccion frente a otros. "],["modelo-de-regresion-lineal.html", "Chapter 3 Modelo de regresion Lineal", " Chapter 3 Modelo de regresion Lineal Comenzamos nuestro planteamiento con el modelo mas basico posible, un modelo que proponga explicar la serie de tiempo en una tendencia lineal creciente, no se extendera mucho en esta parte ya que no hay mucho que explicar modelo_LI &lt;- lm(EST_COL~time(EST_COL)) plot(EST_COL, main = &quot;Comparacion vs modelo lineal&quot;, col = &quot;blue&quot;, ylab = &quot;Valores&quot;) abline(reg = modelo_LI) summary(modelo_LI) ## ## Call: ## lm(formula = EST_COL ~ time(EST_COL)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1155.3 -591.7 207.8 556.9 874.1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4.458e+05 1.254e+04 -35.55 &lt;2e-16 *** ## time(EST_COL) 2.278e+02 6.251e+00 36.45 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 661 on 127 degrees of freedom ## Multiple R-squared: 0.9127, Adjusted R-squared: 0.9121 ## F-statistic: 1328 on 1 and 127 DF, p-value: &lt; 2.2e-16 Ahora, si nosotros observamos la grafica, nos podemos dar cuenta que los datos parecen seguir una tendencia lineal creciente debido a lo bien que la linea recta se ajusta a la serie de tiempo (salvo por supuesto en algunas caidas y desaceleraciones especificas). Este ultimo hecho se afianza cuando al aplicar la prueba del valor P nos damos cuenta que el tiempo es una variable que es muy significativa en el comportamiento del ‘GDP per capita’, ademas de que el modelo lineal abarca alrededor del 90% de la variabilidad de los datos en la serie, basicamente la mayoria de datos. Los hechos anteriores nos podrian indicar que una regresion lineal seria suficiente para explicar el comportamiento de la serie y hacer analisis de prediccion para los años siguientes. Sin embargo, es necesario plantear mas modelos con tecnicas estadisticas distintas para poder comparar al final y tomar una mejor desicion. A partir de aqui sera necesario entonces transformar nuestra serie de tiempo en serie estacionaria, esto debido a que los siguientes modelos que trabajaremos asumiran que nuestra serie tiene propiedades que no cambian en el tiempo, "],["transformacion-a-serie-estacionaria.html", "Chapter 4 Transformacion a serie estacionaria", " Chapter 4 Transformacion a serie estacionaria El primer paso es determinar si nuestra serie presenta estacionariedad, para esto usaremos el test de Dicky-Fuller y plantear a partir de aqui una prueba de Hipotesis adf.test(ST_TRIMESTRAL) ## ## Augmented Dickey-Fuller Test ## ## data: ST_TRIMESTRAL ## Dickey-Fuller = -2.0683, Lag order = 5, p-value = 0.5481 ## alternative hypothesis: stationary H0: La serie NO es estacionaria H1: La serie es estacionaria como el valor P NO es menor a 0.05 NO rechazamos H0 luego la prueba de hipotesis nos dice que esta serie aun no es estacionaria. Es necesario que nuestra serie de tiempo presente estacionariedad para la identificacion de patrones por ende vamos a volverla estacionaria, como? la diferenciaremos hasta volverla estacionaria. Comprobamos primero cuantas veces debemos diferenciarla hasta volverla estacionaria ndiffs(ST_TRIMESTRAL) ## [1] 1 Vemos que es necesario diferenciarla una vez, la definimos y graficamos DIFF1&lt;-diff(ST_TRIMESTRAL) dygraph(DIFF1) %&gt;% dyRangeSelector() # Agrega un selector de rango para el zoom Volvamos a aplicar la prueba de dicky-fuller para asegurarnos que ya trabajamos con estacionariedad adf.test(DIFF1) ## ## Augmented Dickey-Fuller Test ## ## data: DIFF1 ## Dickey-Fuller = -2.9397, Lag order = 5, p-value = 0.1859 ## alternative hypothesis: stationary Como vemos aqui, parece ser que aun no pasa la prueba del valor p, lo que sugiere que la serie es mas tenaz de lo esperado en presentar no estacionariedad, la volvemos a diferenciar DIFF2&lt;-diff(DIFF1) dygraph(DIFF2) %&gt;% dyRangeSelector() # Agrega un selector de rango para el zoom adf.test(DIFF2) ## Warning in adf.test(DIFF2): p-value smaller than printed p-value ## ## Augmented Dickey-Fuller Test ## ## data: DIFF2 ## Dickey-Fuller = -5.8257, Lag order = 5, p-value = 0.01 ## alternative hypothesis: stationary Luego finalmente esta forma diferenciada 2 veces pasa el test por ende sera la serie con la que trabajaremos de ahora en adelante "],["modelo-holt-winters.html", "Chapter 5 Modelo Holt-Winters", " Chapter 5 Modelo Holt-Winters Ahora que ya tenemos nuestra serie estacionaria, es momento de crear otro de los modelos candidatos que pueda predecir el comportamiento de los datos bajo ciertas condiciones. Este modelo sera creado a partir de la tecnica Holt-Winters vista en el curso modelo_HW &lt;- HoltWinters(DIFF2) El parametro seasonal define como se deberia comportar el componente estacional del modelo dependiendo de la instruccion “Addictive” o “Multiplicative” que elijamos. Sin embargo, dado que eliminamos la compomente estacional, no tiene sentido apelar a estas instrucciones, de hacerlo, el modelo intentaria ajustar un componente estacional a los datos y estos, al no tener precisamente estacionalidad, derivaria en incorrectos ajustes. plot(modelo_HW, main=&quot;Ajuste con Holt-Winters&quot;, xlab=&quot;Ao&quot;,ylab=&quot;GDP&quot;) Se puede observar tambien la serie ahora descompuesta por el metodo de Holt-Winters plot(fitted(modelo_HW), main=&quot;Descomposicion con HW&quot;, xlab=&quot;Ao&quot;,ylab=&quot;GDP&quot;) "],["modelo-arima.html", "Chapter 6 Modelo Arima", " Chapter 6 Modelo Arima Continuamos planteando nuestro siguiente modelo candidato, esta vez definiremos un modelo autorregresivo de promedio movil integrado, tambien conocido como modelo ARIMA. Como primer paso, daremos un vistazo a las funciones de autocorrelacion completa (ACF) y parcial (PACF). Estas funciones miden la correlacion entre una serie de tiempo y sus valores retrasados, esto se hace para determinar el rango de los posibles valores p y q de nuestro modelo Arima. NOTA: Recuerdese que la forma del modelo ARIMA es (p,d,q) con d = 2 el nivel de diferenciacion que sufrio nuestra serie de tiempo en pasos anteriores acf(DIFF2, main=&#39;Figura 5.Función de autocorrelación (ACF)&#39;) Luego observamos en el grafico las lineas quesobrepasan el limite punteado horizontal, esto indica los primeros rezagos con una correlacion significativa, en este caso 0 y 1 luego esos son los valores que podria tomar q pacf(DIFF2, main=&#39;Figura 6.Función de autocorrelación parcial (PACF)&#39;) Luego observamos en el grafico que los valores de p pueden ser 0,1 y 2 El siguiente paso seria probar las distintas combinaciones de los modelos arima para distintos valores de p y q que alternen en sus respectivos rangos, para despues escoger el que menor AIC y BIC tenga. Sin embargo, la funcion auto.arima directamente nos ayuda a seleccionar el mejor modelo de forma automatica modelo_AR &lt;- auto.arima(ST_TRIMESTRAL) modelo_AR ## Series: ST_TRIMESTRAL ## ARIMA(1,1,0)(2,0,0)[4] with drift ## ## Coefficients: ## ar1 sar1 sar2 drift ## 0.9122 -0.7417 -0.6696 54.4111 ## s.e. 0.0364 0.0864 0.1145 21.6525 ## ## sigma^2 = 3055: log likelihood = -696.26 ## AIC=1402.52 AICc=1403.01 BIC=1416.78 Aqui se muestra que en efecto hay dos modelos que cumplen la condicion anterior y que ademas poseen el mismo AIC y BIC(son practicamente el mismo): ARIMA(1,1,0) y ARIMA(2,0,0). Como ultimo paso validamos que el modelo ARIMA tenga residuos de ruido blanco (no se correlacionan los errores), para esto aplicaremos la prueba de Ljung-Box residuales&lt;-modelo_AR$residuals qqnorm(residuales) qqline(residuales) Box.test(residuales,type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: residuales ## X-squared = 0.28388, df = 1, p-value = 0.5942 H0: No hay autocorrelacion en los residuos H1: Hay autocorrelacion en los residuos Como el valor P es mayor a 0.05, NO se rechaza H0, luego no se autocorrelacionan los errores e indica que efectivamente cumplen la condicion de ruido blanco Como analisis adicional, aplicaremos la prueba shapiro para determinar si los residuos se distribuyen de manera normal o no lo hacen shapiro.test(residuales) ## ## Shapiro-Wilk normality test ## ## data: residuales ## W = 0.62737, p-value &lt; 2.2e-16 H0: Los residuos siguen una distribucion normal H1: Los residuos NO siguen una distribucion normal Como el valor P es menor a 0.05, se rechaza H0 y la muestra no sigue una distribucion normal "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
